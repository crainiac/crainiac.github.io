Principle of Least Perplexity

Here's a simple "intelligence design" principle: construct next-token predictor learning curricula* by presenting samples from lowest to highest perplexity. With a good perplexity estimator, I conjecture that recursive application of this rule can robustly outperform the absence of its application and enable smaller language models to do things today considered far beyond their capacity.

*Including, but not limited to, pretraining, fine-tuning, and/or in-context learning curricula, with perplexity grouped by window size, minibatch, epoch, and/or hand-assigned labels.

Inspirations:
[1] https://arxiv.org/abs/2101.10382
[2] https://arxiv.org/abs/2206.14486
[3] https://arxiv.org/abs/0812.4360
